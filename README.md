# Удалённый контроль IoT-устройств
---


<img src="https://raw.githubusercontent.com/guff192/IoT-manager/refs/heads/main/assets/AppDiagram.png" width=1080>


## Компоненты приложения
1. **IoT-устройство (Микроконтроллер)**:
	- Отвечает за сбор данных с датчиков и их отправку на сервер (`POST /sensors`).
	- Периодически опрашивает сервер на наличие команд (`GET /commands`).
2. **Веб-приложение (Пользовательский интерфейс):**
	Служит для взаимодействия пользователя с системой:
	- отправки команд на устройства (`POST /commands`) 
	- просмотра данных с датчиков (`GET /sensors`).
3. **Nginx (Прокси-сервер):**
	- Принимает все входящие HTTP-запросы и направляет их на соответствующий *API-сервер*.
	- Может использоваться для SSL-терминирования и балансировки нагрузки.
4. **API-сервер (FastAPI-приложение):**
	Центральный компонент, который обрабатывает все запросы:
	- Для входящих данных с датчиков: получает запросы, добавляет задачи в очередь `sensors data`.
	- Для исходящих команд: получает запросы от веб-приложения, добавляет задачи в очередь `commands data` и, что очень важно, забирает команды из этой очереди по запросу от *IoT-устройства*.
	- Для логгирования команд: после отправки команды в очередь, добавляет информацию о событии в очередь `commands log`.
5. **RabbitMQ (Брокер сообщений):**
	Надёжное хранилище для всех асинхронных задач. Выделено три отдельные очереди:
	- `sensors data`: Для данных, поступающих с устройств.
	- `commands data`: Для команд, ожидающих исполнения устройством.
	- `commands log`: Для записи истории команд в базу данных.
6. **Воркеры (Рабочие процессы Celery):**
	Автономные процессы, которые слушают очереди и выполняют "тяжёлую" работу.
	- Воркер для данных с датчиков: Забирает задачи из очереди `sensors data`, записывает данные в Postgres и обновляет Redis-кэш.
	- Воркер для логгирования: Забирает задачи из очереди `commands log` и записывает историю команд в Postgres.
7. **Хранилище данных:**
	- *Redis-кэш*: Хранит самые свежие данные с датчиков для быстрого доступа.
	- *Postgres*: Долгосрочное хранилище для всех исторических данных с датчиков и истории команд.


## Сценарии работлы
1. **Сбор данных с сенсоров**
	1) *IoT-устройство* считывает данные и отправляет их на *Nginx* (`POST /sensors`).
	2) *Nginx* перенаправляет запрос на *API-сервер*.
	3) *API-сервер* добавляет задачу в очередь `sensors data` в *RabbitMQ* и сразу возвращает подтверждение устройству (`201 Created`).
	4) *Воркер для данных* забирает задачу из очереди, сохраняет данные в *Postgres* и обновляет *Redis-кэш*.
	5) Пользователь с помощью *веб-приложения* запрашивает данные со своих устройств (`GET /sensors`).
	6) *API-сервер* проверяет наличие данных датчиков в *Redis-кэше*, возвращает их если они етсь
2. **Отправка команды устройству**
	1) Пользователь с помощью *веб-приложения* направляет запрос с командой на *Nginx* (`POST /commands`).
	2) *Nginx* перенаправляет запрос на *API-сервер*.
	3) *API-сервер* добавляет задачу в очередь `commands data` и сразу возвращает подтверждение *веб-приложению* (`201 Created`). Также *API-сервер* сразу же добавляет сообщение о созданной задаче в очередь `commands log`.
	4) *Воркер для истории команд* забирает сообщение из очереди `commands log` и сохраняет данные в базу *Postgres*.
	5) *IoT-устройство* опрашивает *API-сервер*  на наличие новых команд (`GET /commands`).
	6) *API-сервер* синхронно забирает задачу из очереди `commands data` и возвращает её в ответе (`200 OK`)
	7) *IoT-устройство* выполняет команду.
